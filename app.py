# -*- coding: utf-8 -*-
"""Animaniac.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gP4yx2f-ABaUHiHkPXrzelT0TdrvoYLO

### Animaniac - A Project on an Anime Recommendation System by Kevin Karia

Importing all the Libraries and Modules
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import warnings

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

warnings.filterwarnings("always")
warnings.filterwarnings("ignore")

"""Creating Dataframes from the Files"""

anime_df = pd.read_csv('anime.csv', dtype=str)

"""Printing the First 5 Entries of the Dataset"""

anime_df.head()

"""Printing the Information about the Dataset"""

anime_df.info()

"""Now we can see that the dataset has the following columns - anime_id, Name, Genre, Type, Episodes, Rating, Members. However we just require Name, Genre and Type. Hence we will be making another datafram with just those columns."""

df = anime_df[['anime_id', 'name', 'genre', 'type']]
df.head()

"""Now lets check for any missing values in our dataset."""

df.isnull().sum().sort_values(ascending=False)

"""We can see that 62 entries have a null entry for Genre and 25 entries have missing values for type. We will drop all the entries with missing values."""

df = df.dropna()
df.isnull().sum().sort_values(ascending=False)

"""Also we need to convert the datatype of the Genre column from Object to String."""

df['genre'] = df['genre'].astype('unicode')

df.info()

"""Now all the columns with missing values have been deleted.
We also just care about animes which have the type as TV. Hence we will be dropping the other entries aswell.
"""

df = df[df['type']=='TV']
df.head()

"""Since all the rows with type other than TV have been dropped, we can also drop the Type column from the dataset."""

df = df[['anime_id', 'name', 'genre']]
df.head()

"""Now for the Recommender we will be using Tf-Idf which stands for Term Frequency - Inverse Document Frequency to find the count frequency and then use cosine-similarity to compute the similarities of the 2 frequency matrices amd then finally use the average of the similarity scores to find recommendations. <br><br>
Term Frequency finds the total number of times a particular word occurs in the entire dataset and gives it a ranking based on it.<br><br>
What Inverse Document Frequency does is that it finds the relevancy of the words. TF treats all words equally irrescpective of their significance. IDF ranks the words based on how important they are with respect to the scenario.
"""

indices = pd.Series(df.index, index = df['name'])

tfidf = TfidfVectorizer(stop_words='english')
count = CountVectorizer(stop_words='english')

tfidf_matrix = tfidf.fit_transform(anime_df['name'])
count_matrix = count.fit_transform(anime_df['genre'].values.astype('U'))

name_similarity = cosine_similarity(tfidf_matrix)
genre_similarity = cosine_similarity(count_matrix)

def get_recommendations(anime):
    i = indices[anime]
    
   # name_score = list(enumerate(name_similarity[i]))
    genre_score = list(enumerate(genre_similarity[i]))

    # x, y = map(list, zip(*genre_score))

    # plt.plot(x, y)
    # plt.xlabel('Anime ID')
    # plt.ylabel('Similarity Score')
    # plt.title('Similarity Scores for Each Anime in the Dataset w.r.t the Anime You Entered')
    # plt.show()

    # name_score = sorted(name_score, key = lambda x: x[0])
    genre_score = sorted(genre_score, key = lambda x: x[0])
    
   # combined_score = [(i, (sc_1 + sc_2) / 2) for (i, sc_1), (_, sc_2) in zip(name_score, genre_score)]
    combined_score = genre_score
    combined_score = sorted(combined_score, key = lambda x: x[1], reverse = True)

    anime_ids = [i[0] for i in combined_score]

    anime_recs = []

    for k in anime_ids:
      name = anime_df.loc[k, 'name'].lower()
      anime = anime.lower()
      if anime not in name and len(anime_recs)<10:
        anime_recs.append(anime_df.loc[k, 'name'])         
    
    recommendations = "\n".join([f"{i + 1}. {v}" for i, v in enumerate(anime_recs)])
    return recommendations

get_recommendations('Death Note')

import gradio as gr

anime = list(df["name"])

def recommend_movies(movie_name):
    recommendations = get_recommendations(movie_name)
    return recommendations

# Create a dropdown input for movie names
input_dropdown = gr.inputs.Dropdown(choices=anime, label="Select an Anime")

# Create an output component for displaying the recommendations
output_text = gr.outputs.Textbox(label="Recommended Anime")

# Create the Gradio interface
gr.Interface(fn=recommend_movies, inputs=input_dropdown, outputs=output_text, title="Animaniac: The Anime Recommendation System").launch(share=True)